[toc]

# AFDetV2: Rethinking the Necessity of the Second Stage for Object Detection from Point Clouds

![image-20230313155855031](2112.09205.AFDetV2.assets/image-20230313155855031.png)

## Abstract

- 目前两种点云3d目标检测主流：single-stage和two-stage，本文研究发现first stage可以产生更加准确的box，此时second stage主要用于更准确的localization
- 本文设计了single-stage anchor-free network AFDetV2，在backbone中加入**self-calibrated convolution block**，增加**keypoint auxiliary supervision**，以及在多任务头中增加**IoU prediction branch**
  - 将predicted IoU score与classification heatmap相乘形成最终的类别得分
  - 改进的backbone有利于box localization
  - rescoring方法有效地结合了object presence confidence 和box regression accuracy

- 在waymo和nuscenes上实现SOTA(包括single和two stage)，并且获得Most Efficient Model

## Introduction

- single-stage：AFDet、VoxelNet、SECOND、SA-SSD、CIA-SSD、PointPillars、[RCD](Range Conditioned Dilated Convolutions for Scale Invariant 3D Object Detection)、Rangedet、[EVC](Every View Counts: Cross-View Consistency in 3D Object Detection with Hybrid-Cylindrical-Spherical Voxelization)
- two-stage：PointRCNN、STD、PointNet++、PartA2、LiDAR R-CNN、PV-RCNN++、Voxel R-CNN、CenterPoint、RSN
- second stage的重要性在于point features可以恢复voxelization造成的positioning误差以及缺失的receptive field，同时classification的confidence map和regression的localization可能并不align well
- 但是近来一些voxel-based方法证明voxel features 同样能达到point-based features的定位效果，所以second stage仅仅是用额外的计算来提高classification score和加强box regression
- 本文发现first stage已经足够产生准确的box localization，因此second stage作用在于加强classification scores
- 关于如何解决misalignment问题，近期的2d工作VarifocalNet就提出IoU-aware classification score来提高localization accuracy，并且3d工作CIA-SSD也提出IoU regression branch结合了classification score rescoring
- 本文工作接近CIA-SSD，但有以下几点不同
  - 本文为anchor-free，从[AFDet](AFDet: Anchor Free One Stage 3D Object
    Detection)扩展而来，而CIA-SSD为anchor-based
  - 本文提出带有multi-scalability和spatial attention的[self-calibrated conv](Improving Convolutional Networks with Self-Calibrated Convolutions)模块，在backbone中起到增大receptive field以及加强semantics的作用
  - 进一步增强box regression，基于3D boxes的4角点和中心点建立auxiliary loss
  - 在single-stage和two-stage之间做了大量实验，证明二阶段网络refining没有必要，同时，为了align：classification score与box regression，利用了IoU prediction branch，修改了rescoring formula

- 本文方法在Waymo Open Dataset和nuScenes Dataset上都实现领先，且证明几个组件：self-calibrated block, keypoint auxiliary loss, and the IoU prediction branch，都能帮助以往的一些方法涨点，如Voxel R-CNN

## Related Work

**Two-Stage LiDAR Detector**

- first stage产生Region of Interests (RoIs)，second stage做refine；如PointRCNN、STD，产生proposal后，用PointNet++提取proposals内的point features，然后pool到二阶段refinement，但是不同proposals有可能汇聚到同一组点，造成geometric information的丢失
- Part-A2设计了RoI-aware point cloud pooling
- LiDAR R-CNN设计了virtual point and boundary offset
- PV-RCNN则通过MLP汇聚point and voxel-wise feature到set of keypoints
- Pyramid R-CNN利用RoI-grid pyramid解决sparsity问题
- Voxel RCNN通过voxel-RoI pooling直接从voxel and BEV feature提取
- 为了提高处理速度，CenterPoint则通过bilinear interpolation简化到five keypoints
- RSN利用了foreground segmentation作为first stage来稀疏化点云，提高了second stage稀疏卷积的效率

**Singe-Stage LiDAR Detector**

- VoxelNet编码的3D voxels，利用到3D conv，非常耗时
- SECOND利用3D sparse conv加速计算
- PointPillars则通过BEV pillars的形式加速encoding，同时可利用2d conv
- CIA-SSD提出IoU prediction branch和一种post-processing method
- AFDet提出anchor-free and NMS free方法

**Different Views**

- Range Conditioned Dilated Convolutions for Scale Invariant 3D Object Detection
- Rangedet: In Defense of Range View for LiDAR-Based 3D Object Detection
- Every View Counts: Cross-View Consistency in 3D Object Detection with Hybrid-Cylindrical-Spherical Voxelization
- End-to-End Multi-View Fusion for 3D Object Detection in LiDAR Point Clouds

**Anchor-Based LiDAR Detector**

- 大部分工作都基于anchor：PointPillars、SECOND、VoxelNet、Voxel-FPN、[CBGS](Classbalanced Grouping and Sampling for Point Cloud 3D object
  Detection)、STD提出新的spherical anchor

**Anchor-free LiDAR Detector**

- 基于关键点，AFDet、RSN、CenterPoint++，目标的centerness
- 多帧预测，3D-MAN：3D Multi-frame Attention Network for Object Detection

## Methods





























